{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ce7085-331f-4a92-8e04-cf301397f3b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /srv/conda/envs/notebook/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /srv/conda/envs/notebook/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: libpysal in /srv/conda/envs/notebook/lib/python3.12/site-packages (4.13.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.10 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from libpysal) (4.13.4)\n",
      "Requirement already satisfied: geopandas>=0.10.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from libpysal) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from libpysal) (2.2.6)\n",
      "Requirement already satisfied: packaging>=22 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from libpysal) (25.0)\n",
      "Requirement already satisfied: pandas>=1.4 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from libpysal) (2.3.0)\n",
      "Requirement already satisfied: platformdirs>=2.0.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from libpysal) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.27 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from libpysal) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.8 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from libpysal) (1.16.0)\n",
      "Requirement already satisfied: shapely>=2.0.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from libpysal) (2.1.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from libpysal) (1.7.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from beautifulsoup4>=4.10->libpysal) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from beautifulsoup4>=4.10->libpysal) (4.14.1)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from geopandas>=0.10.0->libpysal) (0.11.0)\n",
      "Requirement already satisfied: pyproj>=3.5.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from geopandas>=0.10.0->libpysal) (3.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas>=1.4->libpysal) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas>=1.4->libpysal) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas>=1.4->libpysal) (2025.2)\n",
      "Requirement already satisfied: certifi in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pyogrio>=0.7.2->geopandas>=0.10.0->libpysal) (2025.6.15)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.4->libpysal) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests>=2.27->libpysal) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests>=2.27->libpysal) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests>=2.27->libpysal) (1.26.19)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from scikit-learn>=1.1->libpysal) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from scikit-learn>=1.1->libpysal) (3.6.0)\n",
      "Requirement already satisfied: esda in /srv/conda/envs/notebook/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: geopandas>=0.14 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from esda) (1.1.1)\n",
      "Requirement already satisfied: libpysal>=4.12 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from esda) (4.13.0)\n",
      "Requirement already satisfied: numpy>=1.26 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from esda) (2.2.6)\n",
      "Requirement already satisfied: pandas>=2.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from esda) (2.3.0)\n",
      "Requirement already satisfied: scikit-learn>=1.4 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from esda) (1.7.0)\n",
      "Requirement already satisfied: scipy>=1.12 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from esda) (1.16.0)\n",
      "Requirement already satisfied: shapely>=2.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from esda) (2.1.1)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from geopandas>=0.14->esda) (0.11.0)\n",
      "Requirement already satisfied: packaging in /srv/conda/envs/notebook/lib/python3.12/site-packages (from geopandas>=0.14->esda) (25.0)\n",
      "Requirement already satisfied: pyproj>=3.5.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from geopandas>=0.14->esda) (3.7.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.10 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from libpysal>=4.12->esda) (4.13.4)\n",
      "Requirement already satisfied: platformdirs>=2.0.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from libpysal>=4.12->esda) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.27 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from libpysal>=4.12->esda) (2.32.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from beautifulsoup4>=4.10->libpysal>=4.12->esda) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from beautifulsoup4>=4.10->libpysal>=4.12->esda) (4.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas>=2.1->esda) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas>=2.1->esda) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas>=2.1->esda) (2025.2)\n",
      "Requirement already satisfied: certifi in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pyogrio>=0.7.2->geopandas>=0.14->esda) (2025.6.15)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.1->esda) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests>=2.27->libpysal>=4.12->esda) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests>=2.27->libpysal>=4.12->esda) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests>=2.27->libpysal>=4.12->esda) (1.26.19)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from scikit-learn>=1.4->esda) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from scikit-learn>=1.4->esda) (3.6.0)\n",
      "Requirement already satisfied: pysal in /srv/conda/envs/notebook/lib/python3.12/site-packages (25.7)\n",
      "Requirement already satisfied: beautifulsoup4>=4.10 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (4.13.4)\n",
      "Requirement already satisfied: geopandas>=0.10.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (2.2.6)\n",
      "Requirement already satisfied: packaging>=22 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (25.0)\n",
      "Requirement already satisfied: pandas>=1.4 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (2.3.0)\n",
      "Requirement already satisfied: platformdirs>=2.0.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.27 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.8 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (1.16.0)\n",
      "Requirement already satisfied: shapely>=2.0.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (2.1.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (1.7.0)\n",
      "Requirement already satisfied: libpysal>=4.13.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (4.13.0)\n",
      "Requirement already satisfied: access>=1.1.9 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (1.1.9)\n",
      "Requirement already satisfied: esda>=2.7.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (2.7.1)\n",
      "Requirement already satisfied: giddy>=2.3.6 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (2.3.6)\n",
      "Requirement already satisfied: inequality>=1.1.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (1.1.2)\n",
      "Requirement already satisfied: pointpats>=2.5.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (2.5.1)\n",
      "Requirement already satisfied: segregation>=2.5.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (2.5.2)\n",
      "Requirement already satisfied: spaghetti>=1.7.6 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (1.7.6)\n",
      "Requirement already satisfied: mgwr>=2.2.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (2.2.1)\n",
      "Requirement already satisfied: momepy>=0.10.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (0.10.0)\n",
      "Requirement already satisfied: spglm>=1.1.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (1.1.0)\n",
      "Requirement already satisfied: spint>=1.0.7 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (1.0.7)\n",
      "Requirement already satisfied: spreg>=1.8.3 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (1.8.3)\n",
      "Requirement already satisfied: tobler>=0.12.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (0.12.1)\n",
      "Requirement already satisfied: mapclassify>=2.10.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (2.10.0)\n",
      "Requirement already satisfied: splot>=1.1.7 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (1.1.7)\n",
      "Requirement already satisfied: spopt>=0.7.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pysal) (0.7.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from beautifulsoup4>=4.10->pysal) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from beautifulsoup4>=4.10->pysal) (4.14.1)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from geopandas>=0.10.0->pysal) (0.11.0)\n",
      "Requirement already satisfied: pyproj>=3.5.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from geopandas>=0.10.0->pysal) (3.7.1)\n",
      "Requirement already satisfied: quantecon>=0.7 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from giddy>=2.3.6->pysal) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=3.8 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from inequality>=1.1.2->pysal) (3.10.3)\n",
      "Requirement already satisfied: networkx>=3.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from mapclassify>=2.10.0->pysal) (3.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib>=3.8->inequality>=1.1.2->pysal) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib>=3.8->inequality>=1.1.2->pysal) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib>=3.8->inequality>=1.1.2->pysal) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib>=3.8->inequality>=1.1.2->pysal) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib>=3.8->inequality>=1.1.2->pysal) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib>=3.8->inequality>=1.1.2->pysal) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib>=3.8->inequality>=1.1.2->pysal) (2.9.0)\n",
      "Requirement already satisfied: tqdm>=4.65 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from momepy>=0.10.0->pysal) (4.67.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas>=1.4->pysal) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pandas>=1.4->pysal) (2025.2)\n",
      "Requirement already satisfied: certifi in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pyogrio>=0.7.2->geopandas>=0.10.0->pysal) (2025.6.15)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.8->inequality>=1.1.2->pysal) (1.17.0)\n",
      "Requirement already satisfied: numba>=0.49.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from quantecon>=0.7->giddy>=2.3.6->pysal) (0.61.2)\n",
      "Requirement already satisfied: sympy in /srv/conda/envs/notebook/lib/python3.12/site-packages (from quantecon>=0.7->giddy>=2.3.6->pysal) (1.14.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from numba>=0.49.0->quantecon>=0.7->giddy>=2.3.6->pysal) (0.44.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests>=2.27->pysal) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests>=2.27->pysal) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests>=2.27->pysal) (1.26.19)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from scikit-learn>=1.1->pysal) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from scikit-learn>=1.1->pysal) (3.6.0)\n",
      "Requirement already satisfied: deprecation in /srv/conda/envs/notebook/lib/python3.12/site-packages (from segregation>=2.5.2->pysal) (2.1.0)\n",
      "Requirement already satisfied: seaborn in /srv/conda/envs/notebook/lib/python3.12/site-packages (from segregation>=2.5.2->pysal) (0.13.2)\n",
      "Requirement already satisfied: rtree>=1.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from spaghetti>=1.7.6->pysal) (1.4.1)\n",
      "Requirement already satisfied: pulp>=2.8 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from spopt>=0.7.0->pysal) (3.2.2)\n",
      "Requirement already satisfied: rasterio in /srv/conda/envs/notebook/lib/python3.12/site-packages (from tobler>=0.12.1->pysal) (1.4.3)\n",
      "Requirement already satisfied: statsmodels in /srv/conda/envs/notebook/lib/python3.12/site-packages (from tobler>=0.12.1->pysal) (0.14.5)\n",
      "Requirement already satisfied: rasterstats in /srv/conda/envs/notebook/lib/python3.12/site-packages (from tobler>=0.12.1->pysal) (0.20.0)\n",
      "Requirement already satisfied: affine in /srv/conda/envs/notebook/lib/python3.12/site-packages (from rasterio->tobler>=0.12.1->pysal) (2.4.0)\n",
      "Requirement already satisfied: attrs in /srv/conda/envs/notebook/lib/python3.12/site-packages (from rasterio->tobler>=0.12.1->pysal) (25.3.0)\n",
      "Requirement already satisfied: click>=4.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from rasterio->tobler>=0.12.1->pysal) (8.2.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from rasterio->tobler>=0.12.1->pysal) (0.7.2)\n",
      "Requirement already satisfied: click-plugins in /srv/conda/envs/notebook/lib/python3.12/site-packages (from rasterio->tobler>=0.12.1->pysal) (1.1.1.2)\n",
      "Requirement already satisfied: fiona in /srv/conda/envs/notebook/lib/python3.12/site-packages (from rasterstats->tobler>=0.12.1->pysal) (1.10.1)\n",
      "Requirement already satisfied: simplejson in /srv/conda/envs/notebook/lib/python3.12/site-packages (from rasterstats->tobler>=0.12.1->pysal) (3.20.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from statsmodels->tobler>=0.12.1->pysal) (1.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from sympy->quantecon>=0.7->giddy>=2.3.6->pysal) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "!pip install openpyxl\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import scipy.stats as stats\n",
    "!pip install libpysal\n",
    "!pip install esda\n",
    "!pip install pysal\n",
    "from esda.getisord import G_Local\n",
    "from libpysal.weights import Queen\n",
    "from matplotlib.colors import SymLogNorm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy.stats import ttest_ind\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from Getis_Ord import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8d11c9-4f11-4422-a606-7b2ad2f19cb3",
   "metadata": {},
   "source": [
    "# Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e53f2c4-98c0-483d-a76a-b220aef23f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "var = 'returnPeriod_MSWEP_1d'  # Precipitation variable of interest\n",
    "optimal_cluster = 'st_cluster_3_5_7'  # Cluster of interest\n",
    "BASE_CPI = 313.3  # Base CPI for adjustment (e.g., 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a7fc0e-e8b2-494f-a9ae-7cfcf00e1524",
   "metadata": {},
   "source": [
    "# Load Shapefiles of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4fbf2bb-fb62-4ce4-90bf-13f72839fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shapefile for US counties\n",
    "shapefile_path = '../Local_Data/Geospatial/tl_2019_us_county.shp'\n",
    "gdf_counties = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Load the shapefile for US states\n",
    "state_shapefile_path = '../Local_Data/Geospatial/cb_2018_us_state_20m.shp'\n",
    "gdf_states = gpd.read_file(state_shapefile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a59b9ed-9488-4b7e-a967-720c841facd7",
   "metadata": {},
   "source": [
    "# Load County-Aggregated Policy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b61180-0c80-452d-983f-889a630077a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aggregated sum policies by state\n",
    "policies = pd.read_csv(\"../Local_Data/NFIP_Data/policy_total_county_averages.csv\")\n",
    "\n",
    "# Filter out rows with missing or blank values in the relevant columns\n",
    "policies = policies.dropna(subset=['countyCode', 'policyCost_mean', 'totalInsurancePremiumOfThePolicy_mean'])\n",
    "policies['countyCode'] = policies['countyCode'].astype(int).astype(str)\n",
    "policies['countyCode'] = policies['countyCode'].apply(lambda x: str(x).zfill(5))\n",
    "policies['oldest_year'] = policies['oldest_year'] -1 \n",
    "policies['most_recent_year'] = policies['most_recent_year'] -1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641bafdb-f830-4af3-9b85-acbaf3e74399",
   "metadata": {},
   "source": [
    "# Load Claims Precip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2eaf333-8dd6-457f-8e7f-794f7a1e2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load claims data\n",
    "claims1 = pd.read_csv(\"../2_Low_Return_Period/Clusters/no_percentile_filter/clustered_claims_sensitivity.csv\", low_memory=False)\n",
    "# Create the new field 'percentageDamageAmount'\n",
    "claims1['percentageBuildingDamageAmount'] = ((claims1['buildingDamageAmount'] / claims1['buildingPropertyValue']) * 100).clip(upper=100)\n",
    "# Create new field for 'totalClaimPaid'\n",
    "claims1['totalClaimPaid'] = claims1['amountPaidOnBuildingClaim'].fillna(0) + claims1['amountPaidOnContentsClaim'].fillna(0)\n",
    "# Filter stateOwnedIndicator is True\n",
    "claims1 = claims1[claims1['stateOwnedIndicator'] != True]\n",
    "# Create mitigated field\n",
    "claims1['mitigated'] = claims1['elevatedBuildingIndicator'] | claims1['floodproofedIndicator']\n",
    "\n",
    "# Ensure that 'countyCode' is properly formatted as a 5-character string\n",
    "claims1['countyCode'] = claims1['countyCode'].astype(int).astype(str)\n",
    "claims1['countyCode'] = claims1['countyCode'].apply(lambda x: str(x).zfill(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617e1037-0611-47b2-9f9f-674d76738022",
   "metadata": {},
   "source": [
    "# Load Risk Rating 2.0 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1794f65e-5c77-4417-a428-c9535a5373ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_policies = pd.read_excel('../Local_Data/NFIP_Data/nfip_policy-information-by-state_20240531.xlsx', sheet_name='PIF')\n",
    "\n",
    "risk_policies['County'] = risk_policies['County'].str.strip()\n",
    "risk_policies['State'] = risk_policies['State'].str.strip()\n",
    "\n",
    "aggregated_risk_policies = risk_policies.groupby(['County', 'State']).agg({\n",
    "    'Policies in Force': 'sum',\n",
    "    'Total Coverage': 'sum',\n",
    "    'Total Written Premium + FPF': 'sum',\n",
    "    'Total Annual Payment': 'sum'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e5925-17fb-4680-bd89-81b60c867d8d",
   "metadata": {},
   "source": [
    "## Map Fips to appropriate county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "072dc199-fbf3-499f-9b9c-0996826d7bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file line by line\n",
    "with open('../Local_Data/fips_codes.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Identify where state-level data starts and ends\n",
    "state_section_start = 0\n",
    "county_section_start = 0\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if \"state-level\" in line.lower():\n",
    "        state_section_start = i + 2  # State data starts after the \"state-level\" heading\n",
    "    if \"county-level\" in line.lower():\n",
    "        county_section_start = i + 2  # County data starts after the \"county-level\" heading\n",
    "        break\n",
    "\n",
    "# Manually create the dictionary mapping state FIPS codes to state names\n",
    "state_fips_dict = {\n",
    "    \"01\": \"ALABAMA\",\n",
    "    \"02\": \"ALASKA\",\n",
    "    \"04\": \"ARIZONA\",\n",
    "    \"05\": \"ARKANSAS\",\n",
    "    \"06\": \"CALIFORNIA\",\n",
    "    \"08\": \"COLORADO\",\n",
    "    \"09\": \"CONNECTICUT\",\n",
    "    \"10\": \"DELAWARE\",\n",
    "    \"11\": \"DISTRICT OF COLUMBIA\",\n",
    "    \"12\": \"FLORIDA\",\n",
    "    \"13\": \"GEORGIA\",\n",
    "    \"15\": \"HAWAII\",\n",
    "    \"16\": \"IDAHO\",\n",
    "    \"17\": \"ILLINOIS\",\n",
    "    \"18\": \"INDIANA\",\n",
    "    \"19\": \"IOWA\",\n",
    "    \"20\": \"KANSAS\",\n",
    "    \"21\": \"KENTUCKY\",\n",
    "    \"22\": \"LOUISIANA\",\n",
    "    \"23\": \"MAINE\",\n",
    "    \"24\": \"MARYLAND\",\n",
    "    \"25\": \"MASSACHUSETTS\",\n",
    "    \"26\": \"MICHIGAN\",\n",
    "    \"27\": \"MINNESOTA\",\n",
    "    \"28\": \"MISSISSIPPI\",\n",
    "    \"29\": \"MISSOURI\",\n",
    "    \"30\": \"MONTANA\",\n",
    "    \"31\": \"NEBRASKA\",\n",
    "    \"32\": \"NEVADA\",\n",
    "    \"33\": \"NEW HAMPSHIRE\",\n",
    "    \"34\": \"NEW JERSEY\",\n",
    "    \"35\": \"NEW MEXICO\",\n",
    "    \"36\": \"NEW YORK\",\n",
    "    \"37\": \"NORTH CAROLINA\",\n",
    "    \"38\": \"NORTH DAKOTA\",\n",
    "    \"39\": \"OHIO\",\n",
    "    \"40\": \"OKLAHOMA\",\n",
    "    \"41\": \"OREGON\",\n",
    "    \"42\": \"PENNSYLVANIA\",\n",
    "    \"44\": \"RHODE ISLAND\",\n",
    "    \"45\": \"SOUTH CAROLINA\",\n",
    "    \"46\": \"SOUTH DAKOTA\",\n",
    "    \"47\": \"TENNESSEE\",\n",
    "    \"48\": \"TEXAS\",\n",
    "    \"49\": \"UTAH\",\n",
    "    \"50\": \"VERMONT\",\n",
    "    \"51\": \"VIRGINIA\",\n",
    "    \"53\": \"WASHINGTON\",\n",
    "    \"54\": \"WEST VIRGINIA\",\n",
    "    \"55\": \"WISCONSIN\",\n",
    "    \"56\": \"WYOMING\"\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame for easy merging\n",
    "state_df = pd.DataFrame(list(state_fips_dict.items()), columns=['State FIPS', 'State Name'])\n",
    "\n",
    "# Split the data into sections\n",
    "state_section_start = 0\n",
    "county_section_start = 0\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if \"state-level\" in line.lower():\n",
    "        state_section_start = i + 2  # Skip the header lines\n",
    "    if \"county-level\" in line.lower():\n",
    "        county_section_start = i + 2  # Skip the header lines\n",
    "        break\n",
    "\n",
    "state_lines = lines[state_section_start:county_section_start-2]  # State data lines\n",
    "county_lines = lines[county_section_start:]  # County data line\n",
    "\n",
    "# Parse county data\n",
    "county_fips = []\n",
    "county_name = []\n",
    "\n",
    "for line in county_lines:\n",
    "    line = line.strip()\n",
    "    if len(line) > 12 and line[:5].isdigit():\n",
    "        county_fips_code = line[:5].strip()\n",
    "        county_fips_name = line[12:].strip()\n",
    "        county_fips.append(county_fips_code)\n",
    "        county_name.append(county_fips_name)\n",
    "\n",
    "county_df = pd.DataFrame({\n",
    "    'countyCode': county_fips,\n",
    "    'County Name': county_name\n",
    "})\n",
    "\n",
    "county_df['State FIPS'] = county_df['countyCode'].str[:2]  # Extract state FIPS from the countyCode\n",
    "\n",
    "# Merge\n",
    "fips_df = county_df.merge(state_df, on='State FIPS')\n",
    "fips_df['County Name'] = fips_df['County Name'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f183ac3d-85ce-490f-878d-486b65ec6bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that County and State names are fully capitalized in the aggregated_risk_policies DataFrame\n",
    "aggregated_risk_policies['County'] = aggregated_risk_policies['County'].str.upper()\n",
    "aggregated_risk_policies['State'] = aggregated_risk_policies['State'].str.upper()\n",
    "\n",
    "# Merge the DataFrames\n",
    "aggregated_risk_policies = aggregated_risk_policies.merge(fips_df, left_on=['County', 'State'], right_on=['County Name', 'State Name'], how='left')\n",
    "\n",
    "# Drop unnecessary columns (optional)\n",
    "aggregated_risk_policies = aggregated_risk_policies.drop(columns=['County Name', 'State Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d146451-33e5-44f7-8801-34e30f7a8dc9",
   "metadata": {},
   "source": [
    "# Load Clustered Claims Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "664aca88-1ea4-42e2-8677-5ea2d63d9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load claims data\n",
    "claims = pd.read_csv(\"clustered_claims_final.csv\", low_memory=False)\n",
    "\n",
    "# 1) Coerce dtypes\n",
    "num_cols = [\"latitude\", \"longitude\", \"adjustedClaim\"]\n",
    "claims[num_cols] = claims[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "claims[\"dateOfLoss\"] = pd.to_datetime(claims[\"dateOfLoss\"], errors=\"coerce\")\n",
    "claims['countyCode'] = claims['countyCode'].astype(int).astype(str)\n",
    "claims['countyCode'] = claims['countyCode'].apply(lambda x: str(x).zfill(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f144d4-8a67-4e6d-9706-8f510841343f",
   "metadata": {},
   "source": [
    "## Unclustered Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2464f3f8-24b8-4606-8f65-7c2003cb9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter claims to only include rows where optimal_cluster == -1\n",
    "filtered_claims = claims[claims[optimal_cluster] == -1].copy()\n",
    "filtered_claims['countyCode'] = filtered_claims['countyCode'].astype(int).astype(str)\n",
    "filtered_claims['countyCode'] = filtered_claims['countyCode'].apply(lambda x: str(x).zfill(5))\n",
    "\n",
    "# Group by 'countyCode' and count the number of datapoints\n",
    "cluster_counts = filtered_claims.groupby('countyCode').size().reset_index(name='countUncluster')\n",
    "\n",
    "# Merge the grouped counts with gdf_counties based on 'countyCode' and 'GEOID'\n",
    "gdf_counties = gdf_counties.merge(cluster_counts, left_on='GEOID', right_on='countyCode', how='left', suffixes=('', '_drop'))\n",
    "\n",
    "# Drop the duplicate 'countyCode_drop' column from the merge\n",
    "gdf_counties.drop(columns=['countyCode_drop'], inplace=True, errors='ignore')\n",
    "\n",
    "# Replace NaN values with 0 (for counties with no data points)\n",
    "gdf_counties['countUncluster'] = gdf_counties['countUncluster'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32ee64a-5fec-4a28-be0c-a39f77df14bd",
   "metadata": {},
   "source": [
    "# Load Multiple Loss Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0426cf8-23c5-4711-8c06-dba2a833631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_loss = pd.read_csv('../Local_Data/NFIP_Data/NfipMultipleLossProperties.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857c80f-f8e7-4048-ac78-81357b97b427",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c8dc46e-d102-4a53-ae8f-67835bac8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the countyCode is a string with leading zeros if needed\n",
    "multi_loss = multi_loss.dropna(subset=['fipsCountyCode'])\n",
    "multi_loss['fipsCountyCode'] = multi_loss['fipsCountyCode'].astype(int).astype(str)\n",
    "multi_loss['fipsCountyCode'] = multi_loss['fipsCountyCode'].apply(lambda x: str(x).zfill(5))\n",
    "\n",
    "county_multi_loss = multi_loss.groupby(\"fipsCountyCode\").aggregate({\n",
    "    'nfipRl':'sum',\n",
    "    'nfipSrl':'sum',\n",
    "    'fmaRl':'sum',\n",
    "    'fmaSrl':'sum',\n",
    "    'totalLosses':'sum',\n",
    "    'primaryResidenceIndicator':'sum',\n",
    "    'mitigatedIndicator':'sum',\n",
    "    'insuredIndicator':'sum'}).reset_index()\n",
    "county_multi_loss['Rl'] = county_multi_loss['nfipRl']+county_multi_loss['fmaRl']\n",
    "county_multi_loss['Srl'] = county_multi_loss['nfipSrl']+county_multi_loss['fmaSrl']\n",
    "county_multi_loss['totalMultiLossProp'] = county_multi_loss['Rl']+county_multi_loss['Srl']\n",
    "# Avoid division by zero by using np.where\n",
    "county_multi_loss['lossPerProp'] = np.where(county_multi_loss['totalMultiLossProp'] != 0,\n",
    "                                            county_multi_loss['totalLosses'] / county_multi_loss['totalMultiLossProp'],\n",
    "                                            0)\n",
    "\n",
    "county_multi_loss['percentInsured'] = np.where(\n",
    "    county_multi_loss['totalMultiLossProp'] != 0,\n",
    "    (county_multi_loss['insuredIndicator'] / county_multi_loss['totalMultiLossProp'] * 100).clip(upper=100),\n",
    "    0\n",
    ")\n",
    "\n",
    "county_multi_loss['percentMitigated'] = np.where(\n",
    "    county_multi_loss['totalMultiLossProp'] != 0,\n",
    "    (county_multi_loss['mitigatedIndicator'] / county_multi_loss['totalMultiLossProp'] * 100).clip(upper=100),\n",
    "    0\n",
    ")\n",
    "\n",
    "county_multi_loss['percentPrimaryResidence'] = np.where(\n",
    "    county_multi_loss['totalMultiLossProp'] != 0,\n",
    "    (county_multi_loss['primaryResidenceIndicator'] / county_multi_loss['totalMultiLossProp'] * 100).clip(upper=100),\n",
    "    0\n",
    ")\n",
    "\n",
    "# Merge the aggregated data with the shapefile\n",
    "gdf_counties = gdf_counties.merge(county_multi_loss, left_on='GEOID', right_on='fipsCountyCode', how='left')\n",
    "\n",
    "# Load the shapefile for US states\n",
    "state_shapefile_path = '../Local_Data/Geospatial/cb_2018_us_state_20m.shp'\n",
    "gdf_states = gpd.read_file(state_shapefile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a14022-d2a5-48cf-8269-a78adb50275a",
   "metadata": {},
   "source": [
    "# Getis-Ord Hotspot Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "214f86bd-11e0-45ca-b0d7-6d1a2f90e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for countUncluster\n",
    "gdf_counties = run_getis_ord_analysis(gdf_counties, \"countUncluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef39f15-5954-4f9f-98bf-e5672990116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for totalMultiLossProp\n",
    "gdf_counties = run_getis_ord_analysis(gdf_counties, \"totalMultiLossProp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12435ad7-a134-41f2-8cf1-7be21b6da8b5",
   "metadata": {},
   "source": [
    "# Aggregate Unclustered Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed3fd0-25f6-4d94-a609-fde3ba1a0bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_clusters = claims\n",
    "\n",
    "# Filter claims_cluster to only include those from 1998 to present\n",
    "claims_clusters['dateOfLoss'] = pd.to_datetime(claims_clusters['dateOfLoss'])\n",
    "\n",
    "# Define cluster group\n",
    "claims_clusters['Cluster_Group'] = claims_clusters[optimal_cluster].apply(lambda x: 'Unclustered' if x == -1 else 'Clustered')\n",
    "claims1['Cluster_Group'] = claims1[optimal_cluster].apply(lambda x: 'Unclustered' if x == -1 else 'Clustered')\n",
    "\n",
    "# Group by 'optimal_cluster' and calculate medians and sizes\n",
    "cluster_centers = claims_clusters.groupby(optimal_cluster).agg(\n",
    "    median_latitude=('latitude', 'median'),\n",
    "    median_longitude=('longitude', 'median'),\n",
    "    cluster_size=('latitude', 'size'),  # Count rows in each cluster\n",
    "    claim_sum=('adjustedClaim', 'sum'), # Median of the claim_sum for color mapping\n",
    "    median_date=(\"dateOfLoss\", \"median\") \n",
    ").reset_index()\n",
    "\n",
    "sum_unclustered = claims_clusters[claims_clusters[optimal_cluster] == -1]['adjustedClaim'].sum()\n",
    "annual_unclustered = float(sum_unclustered)/(claims_clusters['yearOfLoss'].max()-claims_clusters['yearOfLoss'].min())\n",
    "claim_sum = cluster_centers['claim_sum'].sum()\n",
    "average_claim_sum = float(claim_sum)/(claims_clusters['yearOfLoss'].max()-claims_clusters['yearOfLoss'].min())\n",
    "\n",
    "# Data for the first chart\n",
    "data1 = {\n",
    "    \"Type\": [\"Unclustered\", \"Clustered\"],\n",
    "    \"Value\": [annual_unclustered/1000000, average_claim_sum/1000000]\n",
    "}\n",
    "df1 = pd.DataFrame(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7758822d-007c-4d93-9de3-b8d82c349cef",
   "metadata": {},
   "source": [
    "# Plot 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e72282-3bd7-491a-a632-77ed58e849c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the extent for the contiguous US (longitude and latitude bounds)\n",
    "extent = [-130, -65, 24, 50]  # [min lon, max lon, min lat, max lat]\n",
    "norm_coolwarm = SymLogNorm(linthresh=1, vmin=-10, vmax=10, base=10)\n",
    "\n",
    "# Create the figure with GridSpec for custom column widths\n",
    "fig = plt.figure(figsize=(7.08, 5), constrained_layout=True)\n",
    "gs = GridSpec(2, 2, figure=fig, width_ratios=[2, 1])  # Adjust column width ratios\n",
    "\n",
    "# Subplot a: Uncluster Claims Hotspot\n",
    "ax_a = fig.add_subplot(gs[0, 0])\n",
    "ax_a.set_title('a) Unclustered Claims Hotspot', fontsize=14, loc='left')\n",
    "gdf_counties.plot(\n",
    "    column='Z_Scores_countUncluster', cmap='coolwarm', linewidth=0.01, ax=ax_a,\n",
    "    edgecolor='0.6', norm=norm_coolwarm)\n",
    "gdf_states.boundary.plot(ax=ax_a, edgecolor='black', linewidth=0.6)\n",
    "ax_a.set_xlim(extent[0], extent[1])\n",
    "ax_a.set_ylim(extent[2], extent[3])\n",
    "ax_a.axis('off')\n",
    "\n",
    "# Add colorbar for subplot a\n",
    "sm1 = plt.cm.ScalarMappable(cmap='coolwarm', norm=norm_coolwarm)\n",
    "sm1.set_array([])\n",
    "cbar1 = fig.colorbar(sm1, ax=ax_a, orientation='vertical', location='left', fraction=0.03, pad=0.04)\n",
    "cbar1.set_label('Z-Scores', fontsize=10)\n",
    "\n",
    "# Subplot b: Multiple Loss Properties Hotspot\n",
    "ax_b = fig.add_subplot(gs[1, 0])\n",
    "ax_b.set_title('b) Multiple Loss Properties Hotspot', fontsize=14, loc='left')\n",
    "gdf_counties.plot(\n",
    "    column='Z_Scores_totalMultiLossProp', linewidth=0.01, cmap='coolwarm', norm=norm_coolwarm, ax=ax_b\n",
    ")\n",
    "gdf_states.boundary.plot(ax=ax_b, edgecolor='black', linewidth=0.6)\n",
    "ax_b.set_xlim(extent[0], extent[1])\n",
    "ax_b.set_ylim(extent[2], extent[3])\n",
    "ax_b.axis('off')\n",
    "\n",
    "# Add colorbar for subplot b\n",
    "sm2 = plt.cm.ScalarMappable(cmap='coolwarm', norm=norm_coolwarm)\n",
    "sm2.set_array([])\n",
    "cbar2 = fig.colorbar(sm2, ax=ax_b, orientation='vertical', location='left', fraction=0.03, pad=0.04)\n",
    "cbar2.set_label('Z-Scores', fontsize=10)\n",
    "\n",
    "# Subplot c: Annual Losses (Bar plot)\n",
    "ax_c = fig.add_subplot(gs[0, 1])\n",
    "sns.barplot(ax=ax_c, data=df1, x=\"Type\", y=\"Value\", hue=\"Type\", palette=\"Blues\")\n",
    "ax_c.set_title(\"c) Annual Losses\", fontsize=14, loc='left')\n",
    "ax_c.set_ylabel(\"Claims ($M)\")\n",
    "ax_c.set_xlabel(\"\")\n",
    "ax_c.set_xticks(ax_c.get_xticks())\n",
    "ax_c.set_xticklabels(ax_c.get_xticklabels(), fontsize=8)\n",
    "# Set y-axis to logarithmic scale\n",
    "ax_c.set_yscale('log')\n",
    "\n",
    "# Add labels on top of the bars\n",
    "for bar in ax_c.patches:\n",
    "    height = bar.get_height()  # Get the height of the bar\n",
    "    y_pos = height*0.9\n",
    "    if height > 0:  # Avoid labeling bars with non-positive heights\n",
    "        ax_c.text(\n",
    "            bar.get_x() + bar.get_width() / 2,  # X position of the label\n",
    "            y_pos,  # Y position of the label\n",
    "            f'{height:.0f}',  # Rounded value as a string\n",
    "            ha='center',  # Center align the text\n",
    "            va='bottom',  # Bottom align the text\n",
    "            fontsize=8  # Adjust font size\n",
    "        )\n",
    "\n",
    "# Subplot d: Clustered vs Unclustered (Box plot)\n",
    "ax_d = fig.add_subplot(gs[1, 1])\n",
    "sns.boxplot(\n",
    "    ax=ax_d,\n",
    "    x='Cluster_Group',\n",
    "    y=var,\n",
    "    data=claims1,\n",
    "    order=['Unclustered','Clustered'],\n",
    "    hue=\"Cluster_Group\",\n",
    "    palette=[\"#92BCD9\", \"#ED8D6F\"]\n",
    ")\n",
    "ax_d.set_title(\"d) Precipitation\\nReturn Periods\", fontsize=14, loc='left')\n",
    "ax_d.set_ylabel(\"(YR)\")\n",
    "ax_d.set_xlabel(\"\")\n",
    "ax_d.set_yscale('log')\n",
    "ax_d.set_xticks(ax_c.get_xticks())\n",
    "ax_d.set_xticklabels(ax_c.get_xticklabels(), fontsize=8)\n",
    "\n",
    "\n",
    "# Add median annotations to subplot d\n",
    "medians_clustered = claims1.groupby('Cluster_Group')[var].median()\n",
    "for i, group in enumerate(['Unclustered','Clustered']):\n",
    "    median = medians_clustered.get(group, None)\n",
    "    if median is not None:\n",
    "        ax_d.text(i, median, f'{median:.1f}', ha='center', va='bottom', color='black')\n",
    "\n",
    "if save:\n",
    "    output_path = 'Plots/F6_Unclustered_Hotspot.png'\n",
    "    plt.savefig(output_path, dpi=500, bbox_inches='tight')\n",
    "\n",
    "# Final adjustments and show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
